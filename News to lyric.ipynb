{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News to poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from pprint import pprint\n",
    "from nltk.parse.stanford import StanfordDependencyParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('British', 'JJ'), ('scientist', 'NN'), ('says', 'VBZ'), ('memories', 'NNS'), ('of', 'IN'), ('spending', 'VBG'), ('the', 'DT'), ('night', 'NN'), ('with', 'IN'), ('Marilyn', 'NNP'), ('Monroe', 'NNP'), ('could', 'MD'), ('be', 'VB'), ('implanted', 'VBN'), ('into', 'IN'), ('the', 'DT'), ('brain', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "partial_grammar = \"\"\"\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N | Det N PP | 'I'\n",
    "VP -> V NP | VP PP\n",
    "\"\"\"\n",
    "title = \"British scientist says memories of spending the night with Marilyn Monroe could be implanted into the brain\"\n",
    "title_words = nltk.word_tokenize(title)\n",
    "title_pos = nltk.pos_tag(title_words)\n",
    "print title_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lex_grammar(words_pos):\n",
    "    lexicon = {}\n",
    "    for word, pos in sorted(words_pos, key=lambda (a, b): b):\n",
    "        if pos not in lexicon:\n",
    "            lexicon[pos] = []\n",
    "        lexicon[pos].append(word)\n",
    "    return \"\\n\".join(\"{pos} -> {words}\".format(pos=pos, words=\"|\".join(ws)) for pos, ws in lexicon.iteritems())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "second_part_of_grammar = lex_grammar(title_pos)\n",
    "grammar = partial_grammar + second_part_of_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S -> NP VP\n",
      "PP -> P NP\n",
      "NP -> Det N | Det N PP | 'I'\n",
      "VP -> V NP | VP PP\n",
      "MD -> could\n",
      "VB -> be\n",
      "VBG -> spending\n",
      "NN -> scientist|night|brain\n",
      "VBN -> implanted\n",
      "JJ -> British\n",
      "IN -> of|with|into\n",
      "VBZ -> says\n",
      "DT -> the|the\n",
      "NNS -> memories\n",
      "NNP -> Marilyn|Monroe\n"
     ]
    }
   ],
   "source": [
    "print grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding you should download zip-archive with stanford parser:\n",
    "\n",
    "http://nlp.stanford.edu/software/stanford-parser-full-2015-04-20.zip\n",
    "\n",
    "We need two files from there:\n",
    "- stanford/stanford-parser.jar\n",
    "- stanford/stanford-parser-3.5.2-models.jar\n",
    "\n",
    "Create a directory 'stanford' and put them there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "British scientist says memories of spending the night with Marilyn Monroe could be implanted into the brain\n",
      "[((u'says', u'VBZ'), u'nsubj', (u'scientist', u'NN')),\n",
      " ((u'scientist', u'NN'), u'amod', (u'British', u'JJ')),\n",
      " ((u'says', u'VBZ'), u'dobj', (u'memories', u'NNS')),\n",
      " ((u'memories', u'NNS'), u'nmod', (u'spending', u'NN')),\n",
      " ((u'spending', u'NN'), u'case', (u'of', u'IN')),\n",
      " ((u'says', u'VBZ'), u'nmod:tmod', (u'night', u'NN')),\n",
      " ((u'night', u'NN'), u'det', (u'the', u'DT')),\n",
      " ((u'says', u'VBZ'), u'advcl', (u'implanted', u'VBN')),\n",
      " ((u'implanted', u'VBN'), u'mark', (u'with', u'IN')),\n",
      " ((u'implanted', u'VBN'), u'nsubjpass', (u'Monroe', u'NNP')),\n",
      " ((u'Monroe', u'NNP'), u'compound', (u'Marilyn', u'NNP')),\n",
      " ((u'implanted', u'VBN'), u'aux', (u'could', u'MD')),\n",
      " ((u'implanted', u'VBN'), u'auxpass', (u'be', u'VB')),\n",
      " ((u'implanted', u'VBN'), u'nmod', (u'brain', u'NN')),\n",
      " ((u'brain', u'NN'), u'case', (u'into', u'IN')),\n",
      " ((u'brain', u'NN'), u'det', (u'the', u'DT'))]\n"
     ]
    }
   ],
   "source": [
    "parser = StanfordDependencyParser(path_to_jar='stanford/stanford-parser.jar',\\\n",
    "                                  path_to_models_jar='stanford/stanford-parser-3.5.2-models.jar')\n",
    "parsed_tree = list(parser.parse(title_words))\n",
    "\n",
    "print title\n",
    "pprint(list(parsed_tree[0].triples()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((u'put', u'VBN'), u'nsubjpass', (u'ball', u'NN')),\n",
      " ((u'ball', u'NN'), u'det', (u'A', u'DT')),\n",
      " ((u'put', u'VBN'), u'auxpass', (u'is', u'VBZ')),\n",
      " ((u'put', u'VBN'), u'nmod', (u'box', u'NN')),\n",
      " ((u'box', u'NN'), u'case', (u'into', u'IN')),\n",
      " ((u'box', u'NN'), u'det', (u'the', u'DT'))]\n"
     ]
    }
   ],
   "source": [
    "test_sent = \"A ball is put into the box\"\n",
    "pprint(list(list(parser.parse(test_sent.split(' ')))[0].triples()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Morphological analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def tokenize(s, pattern=r'\\W+'):\n",
    "    return filter(None, re.split(pattern, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There [[u'DH', u'EH1', u'R']]\n",
      "was [[u'W', u'AA1', u'Z'], [u'W', u'AH1', u'Z'], [u'W', u'AH0', u'Z'], [u'W', u'AO1', u'Z']]\n",
      "a [[u'AH0'], [u'EY1']]\n",
      "little [[u'L', u'IH1', u'T', u'AH0', u'L']]\n",
      "guinea [[u'G', u'IH1', u'N', u'IY0']]\n",
      "pig [[u'P', u'IH1', u'G']]\n",
      "Who [[u'HH', u'UW1']]\n",
      "being [[u'B', u'IY1', u'IH0', u'NG']]\n",
      "little [[u'L', u'IH1', u'T', u'AH0', u'L']]\n",
      "was [[u'W', u'AA1', u'Z'], [u'W', u'AH1', u'Z'], [u'W', u'AH0', u'Z'], [u'W', u'AO1', u'Z']]\n",
      "not [[u'N', u'AA1', u'T']]\n",
      "big [[u'B', u'IH1', u'G']]\n",
      "He [[u'HH', u'IY1']]\n",
      "always [[u'AO1', u'L', u'W', u'EY2', u'Z'], [u'AO1', u'L', u'W', u'IY0', u'Z']]\n",
      "walked [[u'W', u'AO1', u'K', u'T']]\n",
      "upon [[u'AH0', u'P', u'AA1', u'N']]\n",
      "his [[u'HH', u'IH1', u'Z'], [u'HH', u'IH0', u'Z']]\n",
      "feet [[u'F', u'IY1', u'T']]\n",
      "And [[u'AH0', u'N', u'D'], [u'AE1', u'N', u'D']]\n",
      "never [[u'N', u'EH1', u'V', u'ER0']]\n",
      "fasted [[u'F', u'AE1', u'S', u'T', u'IH0', u'D']]\n",
      "when [[u'W', u'EH1', u'N'], [u'HH', u'W', u'EH1', u'N'], [u'W', u'IH1', u'N'], [u'HH', u'W', u'IH1', u'N']]\n",
      "he [[u'HH', u'IY1']]\n",
      "eat [[u'IY1', u'T']]\n",
      "When [[u'W', u'EH1', u'N'], [u'HH', u'W', u'EH1', u'N'], [u'W', u'IH1', u'N'], [u'HH', u'W', u'IH1', u'N']]\n",
      "from [[u'F', u'R', u'AH1', u'M'], [u'F', u'ER0', u'M']]\n",
      "a [[u'AH0'], [u'EY1']]\n",
      "place [[u'P', u'L', u'EY1', u'S']]\n",
      "he [[u'HH', u'IY1']]\n",
      "run [[u'R', u'AH1', u'N']]\n",
      "away [[u'AH0', u'W', u'EY1']]\n",
      "He [[u'HH', u'IY1']]\n",
      "never [[u'N', u'EH1', u'V', u'ER0']]\n",
      "at [[u'AE1', u'T']]\n",
      "the [[u'DH', u'AH0'], [u'DH', u'AH1'], [u'DH', u'IY0']]\n",
      "place [[u'P', u'L', u'EY1', u'S']]\n",
      "did [[u'D', u'IH1', u'D'], [u'D', u'IH0', u'D']]\n",
      "stay [[u'S', u'T', u'EY1']]\n",
      "And [[u'AH0', u'N', u'D'], [u'AE1', u'N', u'D']]\n",
      "while [[u'W', u'AY1', u'L'], [u'HH', u'W', u'AY1', u'L']]\n",
      "he [[u'HH', u'IY1']]\n",
      "run [[u'R', u'AH1', u'N']]\n",
      "as [[u'AE1', u'Z'], [u'EH1', u'Z']]\n",
      "I [[u'AY1']]\n",
      "am [[u'AE1', u'M'], [u'EY1', u'EH1', u'M']]\n",
      "told [[u'T', u'OW1', u'L', u'D']]\n",
      "He [[u'HH', u'IY1']]\n",
      "never [[u'N', u'EH1', u'V', u'ER0']]\n",
      "stood [[u'S', u'T', u'UH1', u'D']]\n",
      "still [[u'S', u'T', u'IH1', u'L']]\n",
      "for [[u'F', u'AO1', u'R'], [u'F', u'ER0'], [u'F', u'R', u'ER0']]\n",
      "young [[u'Y', u'AH1', u'NG']]\n",
      "or [[u'AO1', u'R'], [u'ER0']]\n",
      "old [[u'OW1', u'L', u'D']]\n",
      "He [[u'HH', u'IY1']]\n",
      "often [[u'AO1', u'F', u'AH0', u'N'], [u'AO1', u'F', u'T', u'AH0', u'N']]\n",
      "squeaked [[u'S', u'K', u'W', u'IY1', u'K', u'T']]\n",
      "and [[u'AH0', u'N', u'D'], [u'AE1', u'N', u'D']]\n",
      "sometimes [[u'S', u'AH0', u'M', u'T', u'AY1', u'M', u'Z'], [u'S', u'AH1', u'M', u'T', u'AY2', u'M', u'Z']]\n",
      "violent [[u'V', u'AY1', u'AH0', u'L', u'AH0', u'N', u'T'], [u'V', u'AY1', u'L', u'AH0', u'N', u'T']]\n",
      "And [[u'AH0', u'N', u'D'], [u'AE1', u'N', u'D']]\n",
      "when [[u'W', u'EH1', u'N'], [u'HH', u'W', u'EH1', u'N'], [u'W', u'IH1', u'N'], [u'HH', u'W', u'IH1', u'N']]\n",
      "he [[u'HH', u'IY1']]\n",
      "squeaked [[u'S', u'K', u'W', u'IY1', u'K', u'T']]\n",
      "he [[u'HH', u'IY1']]\n",
      "never [[u'N', u'EH1', u'V', u'ER0']]\n",
      "was [[u'W', u'AA1', u'Z'], [u'W', u'AH1', u'Z'], [u'W', u'AH0', u'Z'], [u'W', u'AO1', u'Z']]\n",
      "silent [[u'S', u'AY1', u'L', u'AH0', u'N', u'T']]\n",
      "Though [[u'DH', u'OW1']]\n",
      "never [[u'N', u'EH1', u'V', u'ER0']]\n",
      "instructed [[u'IH0', u'N', u'S', u'T', u'R', u'AH1', u'K', u'T', u'AH0', u'D'], [u'IH0', u'N', u'S', u'T', u'R', u'AH1', u'K', u'T', u'IH0', u'D']]\n",
      "by [[u'B', u'AY1']]\n",
      "a [[u'AH0'], [u'EY1']]\n",
      "cat [[u'K', u'AE1', u'T']]\n",
      "He [[u'HH', u'IY1']]\n",
      "knew [[u'N', u'UW1'], [u'N', u'Y', u'UW1']]\n",
      "a [[u'AH0'], [u'EY1']]\n",
      "mouse [[u'M', u'AW1', u'S']]\n",
      "was [[u'W', u'AA1', u'Z'], [u'W', u'AH1', u'Z'], [u'W', u'AH0', u'Z'], [u'W', u'AO1', u'Z']]\n",
      "not [[u'N', u'AA1', u'T']]\n",
      "a [[u'AH0'], [u'EY1']]\n",
      "rat [[u'R', u'AE1', u'T']]\n",
      "One [[u'W', u'AH1', u'N'], [u'HH', u'W', u'AH1', u'N']]\n",
      "day [[u'D', u'EY1']]\n",
      "as [[u'AE1', u'Z'], [u'EH1', u'Z']]\n",
      "I [[u'AY1']]\n",
      "am [[u'AE1', u'M'], [u'EY1', u'EH1', u'M']]\n",
      "certified [[u'S', u'ER1', u'T', u'AH0', u'F', u'AY2', u'D']]\n",
      "He [[u'HH', u'IY1']]\n",
      "took [[u'T', u'UH1', u'K']]\n",
      "a [[u'AH0'], [u'EY1']]\n",
      "whim [[u'W', u'IH1', u'M'], [u'HH', u'W', u'IH1', u'M']]\n",
      "and [[u'AH0', u'N', u'D'], [u'AE1', u'N', u'D']]\n",
      "fairly [[u'F', u'EH1', u'R', u'L', u'IY0']]\n",
      "died [[u'D', u'AY1', u'D']]\n",
      "And [[u'AH0', u'N', u'D'], [u'AE1', u'N', u'D']]\n",
      "as [[u'AE1', u'Z'], [u'EH1', u'Z']]\n",
      "I [[u'AY1']]\n",
      "am [[u'AE1', u'M'], [u'EY1', u'EH1', u'M']]\n",
      "told [[u'T', u'OW1', u'L', u'D']]\n",
      "by [[u'B', u'AY1']]\n",
      "men [[u'M', u'EH1', u'N']]\n",
      "of [[u'AH1', u'V'], [u'AH0', u'V']]\n",
      "sense [[u'S', u'EH1', u'N', u'S']]\n",
      "He [[u'HH', u'IY1']]\n",
      "never [[u'N', u'EH1', u'V', u'ER0']]\n",
      "has [[u'HH', u'AE1', u'Z'], [u'HH', u'AH0', u'Z']]\n",
      "been [[u'B', u'IH1', u'N'], [u'B', u'AH0', u'N'], [u'B', u'IH0', u'N']]\n",
      "living [[u'L', u'IH1', u'V', u'IH0', u'NG']]\n",
      "since [[u'S', u'IH1', u'N', u'S']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import cmudict\n",
    "d = cmudict.dict()\n",
    "\n",
    "poem_file = open('data/guinea_pig.txt')\n",
    "corpus = poem_file.readlines()\n",
    "poem_file.close()\n",
    "\n",
    "poem_structure = [\n",
    "    (8, [1,3,5,7],),\n",
    "    (8, [1,3,5,7],),\n",
    "    (8, [1,3,5,7],),\n",
    "    (8, [1,3,5,7],),\n",
    "]\n",
    "for line in corpus:\n",
    "    for token in tokenize(line):\n",
    "        print token, d.get(token.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'W', u'AA1', u'Z'] [u'B', u'IH0', u'K', u'AO1', u'Z'] False\n",
      "[u'W', u'AA1', u'Z'] [u'B', u'IH0', u'K', u'AH1', u'Z'] False\n",
      "[u'W', u'AA1', u'Z'] [u'B', u'IH0', u'K', u'AA1', u'Z'] True\n",
      "[u'W', u'AA1', u'Z'] [u'B', u'IH0', u'K', u'AH0', u'Z'] False\n",
      "[u'W', u'AH1', u'Z'] [u'B', u'IH0', u'K', u'AO1', u'Z'] False\n",
      "[u'W', u'AH1', u'Z'] [u'B', u'IH0', u'K', u'AH1', u'Z'] True\n",
      "[u'W', u'AH1', u'Z'] [u'B', u'IH0', u'K', u'AA1', u'Z'] False\n",
      "[u'W', u'AH1', u'Z'] [u'B', u'IH0', u'K', u'AH0', u'Z'] False\n",
      "[u'W', u'AH0', u'Z'] [u'B', u'IH0', u'K', u'AO1', u'Z'] False\n",
      "[u'W', u'AH0', u'Z'] [u'B', u'IH0', u'K', u'AH1', u'Z'] False\n",
      "[u'W', u'AH0', u'Z'] [u'B', u'IH0', u'K', u'AA1', u'Z'] False\n",
      "[u'W', u'AH0', u'Z'] [u'B', u'IH0', u'K', u'AH0', u'Z'] True\n",
      "[u'W', u'AO1', u'Z'] [u'B', u'IH0', u'K', u'AO1', u'Z'] True\n",
      "[u'W', u'AO1', u'Z'] [u'B', u'IH0', u'K', u'AH1', u'Z'] False\n",
      "[u'W', u'AO1', u'Z'] [u'B', u'IH0', u'K', u'AA1', u'Z'] False\n",
      "[u'W', u'AO1', u'Z'] [u'B', u'IH0', u'K', u'AH0', u'Z'] False\n"
     ]
    }
   ],
   "source": [
    "# TODO:\n",
    "def num_of_syllables(phonetic_translation):\n",
    "    number_of_syllables = 0\n",
    "    for el in phonetic_translation:\n",
    "        if el[-1].isdigit() == True:\n",
    "            number_of_syllables += 1\n",
    "        else:\n",
    "            pass\n",
    "    return number_of_syllables\n",
    "        \n",
    "\n",
    "def is_stressed(phoneme):\n",
    "    if phoneme[-1] == '1':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def apply_structure(line):\n",
    "    pass\n",
    "\n",
    "def is_vowel(sound):\n",
    "    return sound[-1].isdigit()\n",
    "\n",
    "def is_rhyme(pron1, pron2):\n",
    "    vowels = [(i, sound) for i, sound in enumerate(pron1) if is_vowel(sound)]\n",
    "    if vowels:\n",
    "        idx, last_vowel = vowels[-1]\n",
    "        return pron1[-(idx + 1):] == pron2[-(idx + 1):]\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "for pron1 in d.get('was'):\n",
    "    for pron2 in d.get('because'):\n",
    "        print pron1, pron2, is_rhyme(pron1, pron2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
