{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News to poems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from pprint import pprint\n",
    "from nltk.parse.stanford import StanfordDependencyParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('British', 'JJ'), ('scientist', 'NN'), ('says', 'VBZ'), ('memories', 'NNS'), ('of', 'IN'), ('spending', 'VBG'), ('the', 'DT'), ('night', 'NN'), ('with', 'IN'), ('Marilyn', 'NNP'), ('Monroe', 'NNP'), ('could', 'MD'), ('be', 'VB'), ('implanted', 'VBN'), ('into', 'IN'), ('the', 'DT'), ('brain', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "partial_grammar = \"\"\"\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N | Det N PP | 'I'\n",
    "VP -> V NP | VP PP\n",
    "\"\"\"\n",
    "title = \"British scientist says memories of spending the night with Marilyn Monroe could be implanted into the brain\"\n",
    "title_words = nltk.word_tokenize(title)\n",
    "title_pos = nltk.pos_tag(title_words)\n",
    "print title_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lex_grammar(words_pos):\n",
    "    lexicon = {}\n",
    "    for word, pos in sorted(words_pos, key=lambda (a, b): b):\n",
    "        if pos not in lexicon:\n",
    "            lexicon[pos] = []\n",
    "        lexicon[pos].append(word)\n",
    "    return \"\\n\".join(\"{pos} -> {words}\".format(pos=pos, words=\"|\".join(ws)) for pos, ws in lexicon.iteritems())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "second_part_of_grammar = lex_grammar(title_pos)\n",
    "grammar = partial_grammar + second_part_of_grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "S -> NP VP\n",
      "PP -> P NP\n",
      "NP -> Det N | Det N PP | 'I'\n",
      "VP -> V NP | VP PP\n",
      "MD -> could\n",
      "VB -> be\n",
      "VBG -> spending\n",
      "NN -> scientist|night|brain\n",
      "VBN -> implanted\n",
      "JJ -> British\n",
      "IN -> of|with|into\n",
      "VBZ -> says\n",
      "DT -> the|the\n",
      "NNS -> memories\n",
      "NNP -> Marilyn|Monroe\n"
     ]
    }
   ],
   "source": [
    "print grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding one should download the zip-archive of the stanford parser:\n",
    "\n",
    "http://nlp.stanford.edu/software/stanford-parser-full-2015-04-20.zip\n",
    "\n",
    "We need only two files from this folder:\n",
    "    - stanford/stanford-parser.jar\n",
    "    - stanford/stanford-parser-3.5.2-models.jar\n",
    "\n",
    "Create a directory called 'stanford' and copy them there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "British scientist says memories of spending the night with Marilyn Monroe could be implanted into the brain\n",
      "[((u'says', u'VBZ'), u'nsubj', (u'scientist', u'NN')),\n",
      " ((u'scientist', u'NN'), u'amod', (u'British', u'JJ')),\n",
      " ((u'says', u'VBZ'), u'dobj', (u'memories', u'NNS')),\n",
      " ((u'memories', u'NNS'), u'nmod', (u'spending', u'NN')),\n",
      " ((u'spending', u'NN'), u'case', (u'of', u'IN')),\n",
      " ((u'says', u'VBZ'), u'nmod:tmod', (u'night', u'NN')),\n",
      " ((u'night', u'NN'), u'det', (u'the', u'DT')),\n",
      " ((u'says', u'VBZ'), u'advcl', (u'implanted', u'VBN')),\n",
      " ((u'implanted', u'VBN'), u'mark', (u'with', u'IN')),\n",
      " ((u'implanted', u'VBN'), u'nsubjpass', (u'Monroe', u'NNP')),\n",
      " ((u'Monroe', u'NNP'), u'compound', (u'Marilyn', u'NNP')),\n",
      " ((u'implanted', u'VBN'), u'aux', (u'could', u'MD')),\n",
      " ((u'implanted', u'VBN'), u'auxpass', (u'be', u'VB')),\n",
      " ((u'implanted', u'VBN'), u'nmod', (u'brain', u'NN')),\n",
      " ((u'brain', u'NN'), u'case', (u'into', u'IN')),\n",
      " ((u'brain', u'NN'), u'det', (u'the', u'DT'))]\n"
     ]
    }
   ],
   "source": [
    "parser = StanfordDependencyParser(path_to_jar='stanford/stanford-parser.jar',\\\n",
    "                                  path_to_models_jar='stanford/stanford-parser-3.5.2-models.jar')\n",
    "parsed_tree = list(parser.parse(title_words))\n",
    "\n",
    "print title\n",
    "pprint(list(parsed_tree[0].triples()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((u'put', u'VBN'), u'nsubjpass', (u'ball', u'NN')),\n",
      " ((u'ball', u'NN'), u'det', (u'A', u'DT')),\n",
      " ((u'put', u'VBN'), u'auxpass', (u'is', u'VBZ')),\n",
      " ((u'put', u'VBN'), u'nmod', (u'box', u'NN')),\n",
      " ((u'box', u'NN'), u'case', (u'into', u'IN')),\n",
      " ((u'box', u'NN'), u'det', (u'the', u'DT'))]\n"
     ]
    }
   ],
   "source": [
    "test_sent = \"A ball is put into the box\"\n",
    "pprint(list(list(parser.parse(test_sent.split(' ')))[0].triples()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Morphological analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def tokenize(s, pattern=r'\\W+'):\n",
    "    return filter(None, re.split(pattern, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import cmudict\n",
    "from itertools import izip_longest, chain\n",
    "stress_dictionary = cmudict.dict()\n",
    "\n",
    "poem_file = open('data/guinea_pig.txt')\n",
    "corpus = poem_file.readlines()\n",
    "poem_file.close()\n",
    "\n",
    "#list of poem structures\n",
    "poem_structure_1 = [\n",
    "    (8, [1,3,5,7],),\n",
    "    (8, [1,3,5,7],),\n",
    "    (8, [1,3,5,7],),\n",
    "    (8, [1,3,5,7],),\n",
    "]\n",
    "# for line in corpus:\n",
    "#     for token in tokenize(line):\n",
    "#         print token, d.get(token.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, 3 python files are imported. The first one is called phonetics.py and contains the following functions:\n",
    "    - def get_phonemes(word)\n",
    "    - def is_vowel(phoneme)\n",
    "    - def is_consonant(phoneme)\n",
    "    - def num_of_syllables(phoneme)\n",
    "    - def is_stressed(phoneme)\n",
    "    - def is_rhyme(phonemes1, phonemes2)\n",
    "    - def stress_mask(phonemes)\n",
    "    ((- def get_phonetic_combinations(words)))\n",
    "The second file is called utils.py and merely contains the function called\n",
    "    - def combinations(*args)\n",
    "Finally there is a file named validate.py. This script contains 2 functions:\n",
    "    - def validate_line(phonemes, structure)\n",
    "    - def validate_couplet(couplet, structure)\n",
    "For more information, consult the files themselves. As they contain docstrings, it becomes clear what input they require and what output they provide.\n",
    "\n",
    "Under # EXAMPLES, one can see how couplets are validated. Each validate function has as input both phonemes or a couplet respectively, as well as a structure. The latter defines the kind of poem we would like to validate. For example, a structure can consist of a rhyme scheme(abab) and a stress pattern(stressed/true, unstressed/false, stressed/true ...).\n",
    "In the output below the caption, the line which fits the requirements from the pattern is chosen from all combinations possible provided by cmudict'. However, cmudict predicted for words consisting of one syllable to be stressed at any time. Therefore,a function making sure one-syllable words can be both stressed ans unstressed has been added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'DH', u'EH0', u'R'], [u'W', u'AA1', u'Z'], [u'AH0'], [u'L', u'IH1', u'T', u'AH0', u'L'], [u'G', u'IH1', u'N', u'IY0'], [u'P', u'IH1', u'G']]\n",
      "\n",
      "[[u'HH', u'UW0'], [u'B', u'IY1', u'IH0', u'NG'], [u'L', u'IH1', u'T', u'AH0', u'L'], [u'W', u'AA1', u'Z'], [u'N', u'AA0', u'T'], [u'B', u'IH1', u'G']]\n",
      "\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import phonetics as ph\n",
    "import utils\n",
    "#import validate\n",
    "\n",
    "\n",
    "# helper function of validate_couplet(x,y)\n",
    "def validate_line(line, structure):\n",
    "    line_phonemes = [] \n",
    "    words = line.split(' ')\n",
    "    for word in words:\n",
    "        word_phonemes = ph.get_phonemes(word)\n",
    "        if len(word_phonemes) == 1:\n",
    "            if ph.num_of_syllables(word_phonemes[0]) == 1:\n",
    "                word_phonemes.append([sound if not ph.is_stressed(sound) else sound.replace('1', '0') for sound in word_phonemes[0]])\n",
    "        line_phonemes.append(word_phonemes)\n",
    "    for candidate in utils.combinations(*line_phonemes):\n",
    "        stresses = ph.stress_mask(chain.from_iterable(candidate))\n",
    "        #print candidate, stresses\n",
    "        if stresses == structure:\n",
    "            return candidate\n",
    "        \n",
    "\n",
    "# returns true or false; does a couplet answer to the above mentioned scheme or not? Do lines (have to) rhyme?\n",
    "def validate_couplet(couplet, structure):\n",
    "    pass\n",
    "\n",
    "\n",
    "# EXAMPLES\n",
    "utils.combinations([1,2,3],[4],[5,6],[7,8,9])\n",
    "print validate_line(\"there was a little guinea pig\", [False, True, False, True, False, True, False, True])\n",
    "print\n",
    "print validate_line(\"who being little was not big\", [False, True, False, True, False, True, False, True])\n",
    "print\n",
    "print ph.is_rhyme(validate_line(\"there was a little guinea pig\", [False, True, False, True, False, True, False, True])[-1],\n",
    "               validate_line(\"who being little was not big\",  [False, True, False, True, False, True, False, True])[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
